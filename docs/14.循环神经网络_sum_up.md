<!-- translation : alex cheen -->
### Creative RNN
### 生成RNN
到现在为止，我们已经训练了一个能够预测未来时刻样本值的模型，正如前文所述，可以用模型来生成新的序列。
为模型提供 长度为 **n_steps** 的种子序列, 比如全零序列，然后通过模型预测下一时刻的值；把该预测值添加到种子序列的末尾，用最后面 长度为 **n_steps** 的序列做为新的种子序列，做下一次预测，以此类推生成预测序列。
如图14-11所示，这个过程产生的序列会跟原始时间序列相似。
![Figure 14-11](../images/chapter_14/14-11.PNG)

```python
sequence = [0.] * n_steps
for iteration in range(300):
	X_batch = np.array(sequence[-n_steps:].reshape(1, n_steps, 1)
	y_pred = sess.run(outputs, feed_dict={X: X_batch}
	sequence.append(y_pred[0, -1, 0]
```
如果你试图把约翰·列侬的唱片塞给一个RNN模型，看它能不能生成下一张《想象》专辑。
(note: 约翰·列侬 有一张专辑《Imagine》（1971)，这里取其双关的意思）
也许你需要一个更强大的RNN网络，它有更多的神经元，层数也更多。下面来探究一下深度RNN。
## 深度RNN
一个朴素的想法就是把一层层神经元堆叠起来，正如图14-12所示的那样，它呈现了一种深度RNN。
![Figure 14-12](../images/chapter_14/14-12.PNG)
为了用TensorFlow实现深度RNN，可先创建一些神经单元，然后堆叠进 **MultiRNNCell** 。
以下代码中创建了3个相同的神经单元（当然也可以用不同类别的、包含不同不同数量神经元(neurons)的神经单元(cells))

```pyton
n_neurons = 100
n_layers = 3

basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)
multi_layer_cell = tf.contrib.rnn.MultiRNNCell([basic_cell] * n_layers)
outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)
```
这些代码就完成了这部分堆叠工作。**status** 变量包含了每层的一个张量(tensor)，这个张量就代表了该层神经单元的最终状态（维度为[**batch_size, n_neurons**])。
如果在创建**MultiRNNCell**时 设置了 **state_is_tuple=False**, 那么**status**变量就变成了单个张量，它包含了每一层的状态，其在列的方向上进行了聚合，（维度为[**batch_size, n_layers\*n_neurons**]。
注意在TensorFlow版本0.11.0之前，status是单个张量是默认设置。

## 在多个GPU上分布式部署深度RNN网络

<!-- todo later -->

## Dropout的应用

对于深层深度RNN，在训练集上很容易过拟合。Dropout是防止过拟合的常用技术。
可以简单的在RNN层之前或之后添加一层Dropout层，但如果需要在RNN层之间应用Dropout技术就需要**DropoutWrapper**。
下面的代码中，每一层的RNN的输入前都应用了Dropout，Dropout的概率为50%。
```python
keep_prob = 0.5

cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)
cell_drop = tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=keep_prob)
multi_layer_cell = tf.contrib.rnn.MultiRNNCell([cell_drop]*n_layers)
rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)
```
同时也可以通过设置**output_keep_prob**来在输出应用Dropout技术。
然而在以上代码中存在的主要问题是，Dropout不管是在训练还是测试时都起作用了，而我们想要的仅仅是在训练时应用Dropout。
很不幸的时DropoutWrapper（还？）不支持 **is_training** 这样一个设置选项。因此必须自己写 Dropout包装类，或者创建两个计算图，一个用来训练，一个用来测试。后则可通过如下面代码这样实现。
```python
import sys
is_training  = (sys.argv[-1] == "train")

X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
y = tf.placeholder(tf.float32, [None, n_steps, n_outputs])
cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)
if is_training:
	cell = tf.contrib.rnn.DropoutWrapper(cell, input_keep_prob=keep_prob)
multi_layer_cell = tf.contrib.rnn.MultiRNNCell([cell]*n_layers)
rnn_outpus, status = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)

[...] # bulid the rest of the graph
init = tf.global_variables_initializer()
saver = tf.train.Saver()

with tf.Session() as sess:
	if is_training:
		init.run()
		for iteration in range(n_iterations):
			[...] # train the model
		save_path = saver.save(sess, "/tmp/my_model.ckpt")
	else:
		saver.restore(sess, "/tmp/my_model.ckpt")
		[...] # use the model
```
 通过以上的方法就能够训练各种RNN网络了。然而对于长序列的RNN训练还言之过早，事情会变得有一些困难。
 那么我们来探讨一下究竟这是为什么和怎么应对呢？
 
## 长时训练的困难
 
 在训练长序列的RNN模型时，那么就需要把RNN在时间维度上展开成很深的神经网络。正如任何深度神经网络一样，其面临着梯度消失/爆炸的问题，使训练无法终止或收敛。
 很多之前讨论过的缓解这种问题的技巧都可以应用在深度展开的RNN网络：好的参数初始化方式，非饱和的激活函数（如ReLU），批规范化（Batch Normalization）， 梯度截断（Gradient Clipping）， 更快的优化器。
即便如此， RNN在处理适中的长序列（如100输入序列）也在训练时表现的很慢。
最简单和常见的方法解决训练时长问题就是在训练阶段仅仅展开限定时间步长的RNN网络，一种称为截断时间反向传播的算法。
在TensorFlow中通过截断输入序列来简单实现这种功能。例如在时间序列预测问题上可以在训练时减小**n_steps**来实现截断。理所当然这种方法会限制模型在长期模式的学习能力。一种变通方案时确保缩短的序列中包含旧数据和新数据，从而使模型获得两者信息（如序列同时包含最近五个月的数据，最近五周的和最近五天的数据）。
问题时如何确保从去年的细分类中获取的数据有效性呢？这期间短暂但重要的事件对后世的影响，甚至时数年后这种影响是否一定要考虑在内呢（如选举结果）？这种方案有其先天的不足之处。
在长的时间训练过程中，第二个要面临的问题时第一个输入的记忆会在长时间运行的RNN网络中逐渐淡去。确实，通过变换的方式，数据穿流在RNN网络之中，每个时间步长后都有一些信息被抛弃掉了。那么在一定时间后，第一个输入实际上会在RNN的状态中消失于无形。
比如说，你想要分析长篇幅的影评的情感类别，影评以“I love this moive”开篇，并辅以各种改善影片的一些建议。试想一下，如果RNN网络逐渐忘记了开头的几个词，RNN网络的判断完全有可能会对影评断章取义。
为了解决其中的问题，各种能够携带长时记忆的神经单元的变种被提出。这些变种是有效的，往往基本形式的神经单元就不怎么被使用了。
首先了解一下最流行的一种长时记忆神经单元：长短时记忆神经单元LSTM。

## LSTM 单元
长短时记忆单元在1997年由S.H. 和 J.S.首次提出（https://goo.gl/j39AGv) [^3]，并在接下来的几年内经过A.G,H.S（https://goo.gl/6BHh81）[^4],W.Z(https://goo.gl/SZ9kzB)[^5] 等数位研究人员的改进逐渐形成。如果把LSTM单元看作一个黑盒，从外围看它和基本形式的记忆单元很相似，但LSTM单元会比基本单元性能更好，收敛更快，能够感知数据的长时依赖。TensorFlow中通过**BasicLSTMCell**实现。
[^3]: "Long Short-Term Memory," S.Hochreiter and J.Schmidhuber(1997)
[^4]: "Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling," H.Sak et al.(2014)
[^5]: "Recurrent Neural Network Regularization," W.Zaremba et al.(2015)

```python
lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)
```

LSTM单元的工作机制是什么呢？在图14-13中展示了基本LSTM单元的结构。
![Figure 14-13](../images/chapter_14/14-13.PNG)


